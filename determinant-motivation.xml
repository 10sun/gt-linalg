<?xml version="1.0" encoding="UTF-8"?>

<!--********************************************************************
Copyright 2017 Georgia Institute of Technology

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation.  A copy of
the license is included in gfdl.xml.
*********************************************************************-->

<section xml:id="section-determinant-motivation">
  <title>Determinants: Motivation and First Examples </title>

  <p>
    We begin by recalling three primary goals of this course:
  </p>

  <p>
    <ol>
      <li> Solving systems of linear equations, a.k.a. solving the matrix equation <m>Ax=b</m> (we've studied this problem in detail).</li>
      <li>Solving the matrix equation <m>Ax=\lambda x</m>, where <m>\lambda</m> is a number (the eigenvalue problem). We are currently studying this problem.</li>
      <li> "Almost solving" the matrix equation <m>Ax=b</m> (we will study this problem).</li>
    </ol>
  </p>

  <p>As we have seen that solving matrix equations <m>Ax=b</m> are much easier if we can find an inverse matrix <m>A^{-1}</m>, it is natural to ask for a numerical procedure to quickly test invertibility of matrices. It turns out that there is a very nice answer to this question, which is provided by the theory of <em>determinants</em>.
  </p>

  <p>Given any <em>square</em> <m>\ n\times n</m> matrix <m>A</m> (there is no such thing as a determinant for a non-square matrix!), the <term>determinant</term> of <m>A</m> is a number, called <m>\det A</m>. We will see several ways to describe this number.
  </p>

  <p>In fact, determinants are actually an instance of something you already know about: volume. Specifically, the <m>n</m> many columns of a square <m>n\times n</m> matrix <m>A</m> are all <m>n</m>-dimensional vectors.
  These <m>n</m> vectors determine a parallelepiped in <m>\R^n</m>, which we will call the <em>parallelepiped for <m>A</m>.</em>
  For example, if <m>A</m> is a <m>2\times2</m> matrix whose columns are non-zero vectors <m>v</m> and <m>w</m>, that is, if <m>A=\spalignmat{v; w}</m>, then we have the parallelogram determined by <m>v</m> and <m>w</m>:
  </p>

  <figure xml:id="PicPar2Vec">
    <caption>The parallelgram determined by two vectors <m>v_1</m> and <m>v_2</m> in <m>\R^2</m></caption>
    <image width="30%">
      <latex-image-code><![CDATA[
\begin{tikzpicture}[thin border nodes]
  \filldraw[fill=seq-orange, fill opacity=.2, very thin]
    (0,0) -- (1,2) -- (3,3) -- (2,1) -- cycle;
  \draw[vector] (0,0) -- node[auto]{$v_1$} (1,2);
  \draw[vector] (0,0) -- node[auto,swap]{$v_2$} (2,1);
  \node at (1.5,1.5) {$P$};
\end{tikzpicture}
      ]]>
      </latex-image-code>
    </image>
  </figure>

  <p>
    Similarly, if <m>A</m> is a <m>3\times3</m> matrix, then we obtain three vectors in <m>\R^3</m>, which define a parallelepiped:
  </p>

  <figure xml:id="PicPar3Vec">
    <caption>The parallelepiped determined by three vectors in
    <m>\R^3</m></caption>
    <image width="30%">
      <latex-image-code><![CDATA[
\begin{tikzpicture}[thin border nodes, myxyz, scale=1.8]
  \filldraw[fill=seq-orange, opacity=.2, very thin]
    (0,0,0) -- (0,-1,0) -- (.3,-1,1) -- (.3,0,1) -- cycle;
  \filldraw[fill=seq-orange, opacity=.2, very thin]
    (0,0,0) -- (0,-1,0) -- (1,-.8,0) -- (1,.2,0) -- cycle;
  \filldraw[fill=seq-orange, opacity=.2, shift={(0,-1,0)}, very thin]
    (0,0,0) -- (1,.2,0) -- (1.3,.2,1) -- (.3,0,1) -- cycle;
  \filldraw[fill=seq-orange, fill opacity=.2, very thin]
    (0,0,0) -- (1,.2,0) -- (1.3,.2,1) -- (.3,0,1) -- cycle;
  \filldraw[fill=seq-orange, fill opacity=.2, shift={(1,.2,0)}, very thin]
    (0,0,0) -- (0,-1,0) -- (.3,-1,1) -- (.3,0,1) -- cycle;
  \filldraw[fill=seq-orange, fill opacity=.2, shift={(.3,0,1)}, very thin]
    (0,0,0) -- (0,-1,0) -- (1,-.8,0) -- (1,.2,0) -- cycle;
  \draw[vector] (0,0,0) -- node[auto,swap] {$v_1$} (1,.2,0);
  \draw[vector, opacity=.4] (0,0,0) -- node[auto,swap] {$v_2$} (0,-1,0);
  \draw[vector] (0,0,0) -- node[auto] {$v_3$} (.3,0,1);
  \node at (1.2,0,1.2) {$P$};
\end{tikzpicture}
      ]]>
      </latex-image-code>
    </image>
  </figure>

  <paragraphs>
    <title>Key Observation</title>
    <p>
      The matrix <m>A</m> is invertible if and only if the parallelepiped for <m>A</m> has non-zero volume, i.e., if and only if the parallelepiped is not "flat".
    </p>
  </paragraphs>

  <p>
    This is not too hard to believe, especially in low-dimensional cases.
    For example, if <m>A</m> is a <m>2\times2</m> matrix whose columns are non-zero vectors <m>v</m> and <m>w</m>, then we know that the matrix is invertible exactly when <m>v</m> and <m>w</m> are linearly independent, which happens exactly when they don't lie on the same line (neither is a scalar multiple of the other). But this occurs exactly when the parallelogram for <m>A</m> in <xref ref="PicPar2Vec"/> isn't "squashed."
  </p>

  <p>We shall later see that the determinant of <m>A</m> is a number associated
  to <m>A</m> whose absolute value <em>is</em> the volume of the parallelepiped
  for <m>A</m>.
  </p>

  <p>
    Before jumping into general formulas for and the definition of the determinant, we consider a few examples. If <m>n=1</m>, then
    we know that a real number <m>a</m> is invertible (i.e., <m>1/a</m> makes sense) exactly when <m>a\neq0</m>. It is thus reasonable to define the determinant of the matrix <m>\spalignmat{a}</m> to simply be <m>a</m> itself. That is, for any real number <m>a</m>, we have
    <me>\det\mat{a}=a.</me>
    In this case, we can also think of <m>1</m>-dimensional "volume" as length, and the "parallelepiped for <m>A</m>" is just the vector <m>a</m> in <m>\R^1</m>.
  </p>

  <p>
  In the case of a <m>2\times2</m> matrix <m> A=\mat{a b; c d}</m>, the explicit formula is
  <me>\det A =ad-bc.</me>
  It may seem that this formula has little to do with volume. However, it is a fun geometry problem to show that the parallelogram for <m>A</m> in <xref ref="PicPar2Vec"/> has area <m>|ad-bc|</m> (first think about the case when the first column of <m>A</m> lies on the <m>x</m>-axis). As another fun problem, one can perform row reduction directly on <m>A</m> to find that the reduced row echelon form of <m>A</m> is the identity matrix <m>I_2</m> exactly when <m>ad-bc\neq0</m> (although we omit the calculation here).
  </p>

  <p>
  When <m>n=3</m>, the formula for the determinant is a little stranger:
  <me>\begin{split}
  &amp;
  \det\spalignmat{a_{11},a_{12},a_{13}; a_{21},a_{22},a_{23};a_{31},a_{32},a_{33}}
  \\
  &amp;
  \quad\quad
  =
  a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}
  -a_{13}a_{22}a_{31}-a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}.
  \end{split}
  </me>
  This formula looks too complicated to memorize outright. Fortunately, there is a useful mnemonic device for this formula, known as the <em>Rule of Sarrus</em>. This works by drawing a bigger matrix by recopying down the first two columns to the right of the matrix, and by drawing a series of upwards and downwards slashes as follows:
  </p>

  <figure>
    <caption>A useful trick for finding <m>3\times3</m> determinants</caption>
    <image width="100%">
      <latex-image-code><![CDATA[
      \begin{tikzpicture}
      \matrix (a) [matrix of math nodes, anchor=south east] {
      a_{11} \& a_{12} \& a_{13} \& a_{14} \& a_{15} \\
      \llap{$+\quad$}a_{21} \& a_{22} \& a_{23} \& a_{24} \& a_{25} \\
      a_{21} \& a_{22} \& a_{23} \& a_{24} \& a_{25} \\
      };

      \matrix (b) [matrix of math nodes, anchor=south west, xshift=1.5em] {
      a_{11} \& a_{12} \& a_{13} \& a_{14} \& a_{15} \\
      \llap{$-\quad$}a_{21} \& a_{22} \& a_{23} \& a_{24} \& a_{25} \\
      a_{21} \& a_{22} \& a_{23} \& a_{24} \& a_{25} \\
      };

      \begin{scope}[very thick, opacity=.75]
        \draw[seq-green] (a-1-1.north west) -- (a-3-3.south east);
        \draw[seq-green] (a-1-2.north west) -- (a-3-4.south east);
        \draw[seq-green] (a-1-3.north west) -- (a-3-5.south east);
        \draw[seq-blue]  (b-1-3.north east) -- (b-3-1.south west);
        \draw[seq-blue]  (b-1-4.north east) -- (b-3-2.south west);
        \draw[seq-blue]  (b-1-5.north east) -- (b-3-3.south west);
      \end{scope}

      \node at (0, -1em)
        {$\color{seq-green}a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}
          \color{seq-blue}-a_{13}a_{22}a_{31}-a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}$};

      \end{tikzpicture}
      ]]>
      </latex-image-code>
    </image>
  </figure>

  <p>
    Then, we multiply all the entries on each slash together, and add the products of the downward ones, and subtract the products of the upwards ones. For example, to find the determinant of <m>A=\mat{1 3 5; 2 0 -1; 4 -3 1}</m>, we draw the picture
  </p>

  <figure>
    <caption>The <m>3\times3</m> determinant trick for the matrix <m>A</m></caption>
    <image width="35%">
      <latex-image-code><![CDATA[
      \begin{tikzpicture}
        \matrix (a) [matrix of math nodes, nodes={minimum width=2em}]
        { 1 \& 3 \& 5 \& 1\& 3 \\
          2 \& 0 \& -1 \& 2 \& 0 \\
          4 \& -3 \& 1  \& 4 \& -3 \\
        };

      \begin{scope}[very thick, opacity=.75]
        \draw[seq-green] (a-1-1.north west) -- (a-3-3.south east);
        \draw[seq-green] (a-1-2.north west) -- (a-3-4.south east);
        \draw[seq-green] (a-1-3.north west) -- (a-3-5.south east);
        \draw[seq-blue]  (a-1-3.north east) -- (a-3-1.south west);
        \draw[seq-blue]  (a-1-4.north east) -- (a-3-2.south west);
        \draw[seq-blue]  (a-1-5.north east) -- (a-3-3.south west);
      \end{scope}
      \end{tikzpicture}
      ]]>
      </latex-image-code>
    </image>
  </figure>

  <p>
  and find that the determinant of <m>A</m> is
  <me>
  \begin{aligned}
  &amp; \textcolor{seq-green}{1\cdot0\cdot1+3\cdot(-1)\cdot4+5\cdot2\cdot(-3)}
  \textcolor{seq-blue}{-4\cdot0\cdot5-(-3)\cdot(-1)\cdot1-\cdot(1)\cdot2\cdot3}
  \\
  &amp; \quad = 0-12-30-0-3-6 = -51.
  \end{aligned}
  </me>
  </p>

  <p>
  Beoynd <m>n=3</m>, the formula for the determinant gets more complicated. In the subsequent sections, we will give several different ways for computing the determinant, we will apply them to give a general formula for the inverse of a matrix, and we will see how they can be thought of as stretch factors for linear transformations. That’s a lot to do, so let’s get going!
  </p>


</section>
