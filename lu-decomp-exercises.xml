<?xml version="1.0" encoding="UTF-8"?>
<!--********************************************************************
Copyright 2017 Georgia Institute of Technology

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation.  A copy of
the license is included in gfdl.xml.
*********************************************************************-->
<exercises>
    <exercise>
        <statement>
            <p>What is the LU decomposition good for? Your reasoning should involve computational efficiency of LU factorization versus solving <m>Ax=b</m> directly.</p>
        </statement>
    </exercise>
    <exercise>
    	<statement>
    		<p>[MIT OCW] The question is about the matrix
    			<me>A=\mat{1 2 0 1; 2 4 1 4;3 6 3 9}</me>
    			Find a lower triangular <m>L</m> and an upper triangular <m>U</m> so that <m>A=LU</m>.
    		</p>
    	</statement>
    	<answer>
    		<p>
    			<me>A=\mat{1 0 0; 2 1 0; 3 3 1}\mat{1 2 0 1;0 0 1 2; 0 0 0 0}</me>
    		</p>
    	</answer>
    </exercise>
    <exercise>
    	<statement>
    		<p>[MIT OCW] A matrix <m>A=LU</m> has the LU factors
    			<me>L=\mat{1; -2 1; 0 -2 1; -1 -1 -2 1}, U=\mat{1 -1 -2 0;1 0 -2;1 0; 1}</me>
    			<ol>
    				<li>If <m>b=\vec{-1 2 2 -4}</m>, what is <m>x=A\inv b</m>?</li>
    				<li>Assuming you solved the previous part efficiently, roughly how much more arithmetic operations would be required for the same approach if the matrices were <m>8 \times 8</m> instead of <m>4 \times 4</m>? It should be about <fillin/> times more.</li>
    				<li>If you form a new <m>4 \times 5</m> matrix <m>B=\vec{A b}</m> by appending the vector <m>b</m> (from above) as the extra column after <m>A</m>, and perform same elimination steps 
    				as were used to get the LU factors above, what upper-triangular matrix would you obtain?</li>
    			</ol>
    		</p>
    	</statement>
    	<answer>
    		<p>
    			<ol>
    				<li>If <m>x=A\inv b</m>, then <m>b=Ax=LUx</m>. So, to solve for <m>x</m> we can solve the equation <m>b=Ly</m> for <m>y</m> and then <m>y=Ux</m> for <m>x</m>, and these can be solved by forward/back substitution. The forward substituion 
    			procedure for solving for <m>y</m> gives:
    					<md>
    						<mrow>
    							y_1 = -1
    						</mrow>
    						<mrow>
    							-2y_1 + y+2 = 2 \implies y_2 = 2 + 2y_1 = 2 + 2 \star (-1)=0
    						</mrow>
    						<mrow>
    							0y_1 - 2y_2 + y_3 =2 \implies y_3 = 2 + 2y_2 = 2 + 2 \star 0 = 2
    						</mrow>
    						<mrow>
    							-y_1 - y_2 - 2y_2 +y_4 = -4 \implies y_4 = -4+y_1+y_2+2y_3 
    						</mrow>
    						<mrow>
    							\qquad = -4+(-1)+0+2\star 2 = -1
    						</mrow>
    					</md>
    					Then we can solve for <m>x</m> using back substitution:
    					<md>
    						<mrow>	
    							x_4 = -1
    						</mrow>
    						<mrow>
    							x_3 = 2
    						</mrow>
    						<mrow>
    							x_2 - 2x_4 = 0 \implies x_2 = 2x_4 = -2
    						</mrow>
    						<mrow>
    							x_1 - x_2 - 2x_3 = -1 \implies x_1 = -1 + x_2 + 2x_3 = -1 + (-2) + 2*2 = 1
    						</mrow>
    					</md>
    					So the solution is <m>x=(1, -2, 2, -1)</m>
    				</li>
    				<li>Back or forward substitution for <m>m \times m</m> systems require <m>m^2</m> operations. So, the ratio of the time required for <m>m=8</m> and <m>m=4</m> is about <m>8^2/4^2 = 2^2 = 4</m>.</li>
    				<li>Recall that row operations are given by multiplication on the left by an invertible matrix. The Gaussian elimination giving <m>U</m> from <m>A</m> is given by multiplication by an elimination matrix <m>E</m>, i.e. <m>EA=U</m>, and therefore <m>E=L\inv</m>. So, performing the same elimination steps to <m>B=\vec{A b}</m> gives <m>L\inv B = (L\inv AL\inv b)=(U, L\inv b)</m>. In part(1) we solved <m>Ly=b</m> for <m>y</m>, so that <m>L\inv b = y = (-1, 0, 2, -1)</m>. So we obtain the matrix <m>\mat{U y}</m> with <m>U</m> as in the 
    				problem statement and <m>y</m> as computed in the solution to part (1).</li>
    			</ol>
    		</p>
    	</answer>
    </exercise>
    <exercise>
    	<statement>
    		<p>[MIT OCW] Suppose you are given the <m>PA=LU</m> factorization of an invertible <m>n \times n</m> matrix <m>A</m>. Now, suppose we want to solve
    			<me>\mat{A B; 0 A}x = b</me>
    			for some <m>n \times n</m> matrix <m>B</m>, where <q>0</q> denotes an <m>n \times n</m> block of zeros in the lower-left corner.
    			Suppose we express <m>x=\vec{x_1 x_2}</m>, where <m>x_1</m> and <m>x_2</m> are <m>n</m>-component vectors. Similarily we express <m>b=\vec{b_1 b_2}</m> in terms of <m>n</m>-component vectors <m>b_1</m> and <m>b_2</m>. 
    				Write the solution <m>x_1</m> and <m>x_2</m> in terms of <m>P</m>, <m>L</m>, <m>U</m>, <m>B</m>, <m>b_1</m>, <m>b_2</m> (or the inverses of those matrices). <em>Hint</em>: write out two <m>n \times n</m> equations involving <m>x_1</m> and <m>x_2</m> first.
    		</p>
    	</statement>
    	<answer>
    		<p>If we write
    			<me>x=\vec{x_1 x_2}, b=\vec{b_1 b_2}</me>,
    			where <m>x_1</m>, <m>x_2</m>, <m>b_1</m>, <m>b_2</m> are <m>n</m>-dimensional vectors, the system becomes
    			<me>\syseq{Ax_1 + Bx_2 = b_1; Ax_2=b_2}</me>
    			From the second line, we immediately see that
    			<me>x_2 = U\inv (L\inv(Pb_2)</me>.
    			<me>x_1=U\inv(L\inv(P(b_1-Bx_2))) = U\inv(L\inv(P(b_1-B(U\inv(L\inv(Pb_2))))))</me>.
    		</p>
    	</answer>
    </exercise>
</exercises>
